content_lookup:
  cache_enabled: true
  cache_ttl_hours: 168
  dtdd_api_key: ''
logging:
  level: INFO
  log_file: ''
  show_progress: true
nudity:
  body_parts: []
  buffer_after: 0.25
  buffer_before: 0.25
  frame_interval: 0.15
  merge_gap: 0.5
  min_cut_duration: 0.3
  min_segment_duration: 0.5
  threshold: 0.75  # Raised to reduce false positives
  min_box_area_percent: 3.0  # Reject detections smaller than 3% of frame
  max_aspect_ratio: 4.0  # Reject extreme aspect ratios (noise/artifacts)
  scene_gap: 5.0  # Seconds - group nearby detections into scenes for review
output:
  audio_bitrate: 192k
  audio_codec: aac
  custom_output_dir: ''
  default_pattern: '{input}_censored'
  hardware_acceleration: auto
  quality_preset: 1080p_high
  video_codec: libx264
  video_crf: 23
  video_format: mp4
performance:
  parallel_detection: true
  gpu_memory_limit: null  # e.g. "4GB"
  fallback_to_sequential: true
  stagger_delay: 2.0
sync:
  enabled: false
  auto_sync: true
  supabase_url: ""
  supabase_key: ""
  user_id: ""
profanity:
  beep_frequency_hz: 1000
  beep_volume: 0.5
  buffer_after: 0.15
  buffer_before: 0.1
  censor_mode: beep
  custom_phrases_path: ''
  custom_wordlist_path: ''
  dynamic_buffer: true
  dynamic_buffer_factor: 0.02
  merge_gap: 0.3
  
  # Severity Overrides (New)
  # Customize how specific words are categorized
  # Available tiers: severe, moderate, mild, religious
  severity_overrides:
    "heck": "mild"
    "darn": "mild"
    "god": "religious"    # Default
    "freaking": "mild"
    
  # Custom Tiers (Optional - Add your own priority groups)
  # Tiers are for sorting and grouping only (no auto-skip)
  # order: Lower number = Higher priority (top of list)
  custom_tiers:
    - name: "my_priority"
      order: 0
      color: "#FF00FF"
      words: ["specific", "words", "here"]
sexual_content:
  buffer_after: 0.25
  buffer_before: 0.25
  custom_phrases_path: ''
  custom_terms_path: ''
  debug: false
  enabled: true
  merge_gap: 0.5
  threshold: 1.0
  unsafe_threshold: 0.5
whisper:
  compute_type: int8
  language: en
  model_size: large-v3

# LLM-based context analysis (optional)
# Use to reduce false positives by checking if profanity is quoted/discussed
llm:
  enabled: false  # Set to true to enable
  provider: ollama  # ollama, anthropic, openai
  model: ""  # Leave empty for provider default, or specify model
  api_key: ""  # Required for anthropic/openai
  timeout: 5  # Seconds per request
